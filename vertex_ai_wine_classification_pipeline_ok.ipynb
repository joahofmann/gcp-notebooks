{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joahofmann/gcp-notebooks/blob/main/vertex_ai_wine_classification_pipeline_ok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b59cd86"
      },
      "source": [
        "# Vertex AI Pipelines Example\n",
        "\n",
        "This notebook demonstrates how to create and run a simple Kubeflow pipeline on Vertex AI."
      ],
      "id": "2b59cd86"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43b81849"
      },
      "source": [
        "# 1. Setup and Authentication"
      ],
      "id": "43b81849"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32d43e95"
      },
      "source": [
        "# Install necessary libraries\n",
        "!pip install --upgrade google-cloud-aiplatform google-cloud-storage kfp google-cloud-pipeline-components --quiet"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "32d43e95"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0680f577"
      },
      "source": [
        "# Restart runtime (Colab only)\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    import IPython\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0680f577"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c138e493"
      },
      "source": [
        "# Authenticate to Google Cloud\n",
        "# If you are running this in a Colab environment, this will open a browser window for authentication.\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c138e493"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47012516"
      },
      "source": [
        "# --- User-defined variables ---\n",
        "# Replace with your actual project ID and region\n",
        "PROJECT_ID = \"vertex-test-id\" # @param {type:\"string\"}\n",
        "REGION = \"us-central1\" # @param {type:\"string\"}\n",
        "BUCKET_NAME = \"gcs-bucket-name-wine2\" # @param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "47012516"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d1c28f5"
      },
      "source": [
        "# Validate inputs\n",
        "if PROJECT_ID == \"your-gcp-project-id\" or not PROJECT_ID:\n",
        "    raise ValueError(\"Please replace 'your-gcp-project-id' with your actual GCP project ID.\")\n",
        "if BUCKET_NAME == \"your-gcs-bucket-name\" or not BUCKET_NAME:\n",
        "    raise ValueError(\"Please replace 'your-gcs-bucket-name' with your actual GCS bucket name.\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0d1c28f5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1a15351"
      },
      "source": [
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
        "PIPELINE_ROOT = f\"{BUCKET_URI}/pipeline_root_simple_example\"\n",
        "\n",
        "print(f\"Project ID: {PROJECT_ID}\")\n",
        "print(f\"Region: {REGION}\")\n",
        "print(f\"Bucket URI: {BUCKET_URI}\")\n",
        "print(f\"Pipeline Root: {PIPELINE_ROOT}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f1a15351"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c53447e3"
      },
      "source": [
        "### Create a Cloud Storage bucket (if it doesn't exist)\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ],
      "id": "c53447e3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ada224e"
      },
      "source": [
        "# You only need to run this if your bucket doesn't already exist\n",
        "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "5ada224e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db7fd687"
      },
      "source": [
        "# Initialize Vertex AI SDK\n",
        "from google.cloud import aiplatform\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "db7fd687"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c20b313f"
      },
      "source": [
        "# Get the service account\n",
        "SERVICE_ACCOUNT = !gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n",
        "SERVICE_ACCOUNT = f\"{SERVICE_ACCOUNT[0].strip()}-compute@developer.gserviceaccount.com\"\n",
        "print(f\"Service Account: {SERVICE_ACCOUNT}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c20b313f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grant necessary permissions to the Compute Engine default service account.\n",
        "Grant roles/storage.objectAdmin and roles/aiplatform.user to the service account at the project level."
      ],
      "metadata": {
        "id": "nbirvLDXia_A"
      },
      "id": "nbirvLDXia_A"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aiSjN47HNcPW"
      },
      "id": "aiSjN47HNcPW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78fff607"
      },
      "source": [
        "# Grant necessary permissions to the Compute Engine default service account at the project level\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=\"serviceAccount:{SERVICE_ACCOUNT}\" --role=\"roles/storage.objectAdmin\"\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=\"serviceAccount:{SERVICE_ACCOUNT}\" --role=\"roles/aiplatform.user\"\n",
        "\n",
        "#!gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectAdmin {BUCKET_URI}"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "78fff607"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_goNU8zZrbXa"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_goNU8zZrbXa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set service account access for Vertex AI Pipelines. Run the following commands to grant your service account access to read and write pipeline artifacts in the bucket that you created in the previous step. You only need to run these once per service account."
      ],
      "metadata": {
        "id": "MDmWL06ifjik"
      },
      "id": "MDmWL06ifjik"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovArRTbqPpT2"
      },
      "outputs": [],
      "source": [
        "#! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
        "\n",
        "#! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
      ],
      "id": "ovArRTbqPpT2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_vars"
      },
      "source": [
        "### Import libraries and define constants"
      ],
      "id": "setup_vars"
    },
    {
      "cell_type": "code",
      "source": [
        "import google.cloud.aiplatform as aip\n",
        "from kfp import compiler, dsl\n",
        "from kfp.dsl import ClassificationMetrics, Metrics, Output, component"
      ],
      "metadata": {
        "id": "s5ApgwTIbDwq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "s5ApgwTIbDwq"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wnnNKAbhbDtG"
      },
      "execution_count": null,
      "outputs": [],
      "id": "wnnNKAbhbDtG"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_oneFUTYdqwo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_oneFUTYdqwo"
    },
    {
      "cell_type": "code",
      "source": [
        "import kfp.dsl as dsl\n",
        "from kfp.dsl import (Artifact,\n",
        "                        Dataset,\n",
        "                        Input,\n",
        "                        Model,\n",
        "                        Output,\n",
        "                        Metrics,\n",
        "                        ClassificationMetrics,\n",
        "                        component,\n",
        "                        OutputPath,\n",
        "                        InputPath)\n",
        "\n",
        "from typing import NamedTuple\n",
        "from datetime import datetime\n",
        "import os # Import os for path manipulation if needed\n",
        "from google.cloud.aiplatform import pipeline_jobs\n",
        "import json\n",
        "\n",
        "# --- Global Configuration Placeholders ---\n",
        "# IMPORTANT: Replace these with your actual GCP project ID, bucket, and region.\n",
        "# These variables need to be defined before they are used in the pipeline definition.\n",
        "####PROJECT_ID = \"vertex-test-id\" # e.g., \"my-gcp-project-12345\"\n",
        "#REGION = LOCATION             # e.g., \"us-central1\" or \"europe-west1\"\n",
        "# Define a GCS bucket path where pipeline artifacts will be stored.\n",
        "# Ensure this bucket exists and your service account has write permissions.\n",
        "####PIPELINE_ROOT = f\"gs://your-kfp-pipeline-bucket/wine-quality-pipeline-root\"\n",
        "\n",
        "# Generate a timestamp for unique display names for pipeline runs\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "DISPLAY_NAME = f'pipeline-winequality-job-{TIMESTAMP}'"
      ],
      "metadata": {
        "id": "7lOBhvevdrUI"
      },
      "execution_count": null,
      "outputs": [],
      "id": "7lOBhvevdrUI"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ctyGiuBdrUJ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_ctyGiuBdrUJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "459d2b87"
      },
      "source": [
        "# Create pipeline\n",
        "\n",
        "We create 4 components:  \n",
        "- Load data   \n",
        "- Train a  model\n",
        "- Evaluate the model\n",
        "- Deploy the model\n",
        "\n",
        "The components have dependencies on `pandas`, `sklearn`."
      ],
      "id": "459d2b87"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f5diz9crbDpu"
      },
      "execution_count": null,
      "outputs": [],
      "id": "f5diz9crbDpu"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SRxon47IbDj2"
      },
      "execution_count": null,
      "outputs": [],
      "id": "SRxon47IbDj2"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dzdi7aWzbDIQ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Dzdi7aWzbDIQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pipeline_constants"
      },
      "source": [
        "#### Vertex AI constants\n",
        "\n",
        "Setup up the following constants for Vertex AI pipelines:\n",
        "- `PIPELINE_NAME`: Set name for the pipeline.\n",
        "- `PIPELINE_ROOT`: Cloud Storage bucket path to store pipeline artifacts."
      ],
      "id": "pipeline_constants"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0UUB32aPpT3"
      },
      "outputs": [],
      "source": [
        "#PIPELINE_NAME = \"metrics-pipeline-v2\"\n",
        "#PIPELINE_ROOT = \"{}/pipeline_root/iris\".format(BUCKET_URI)"
      ],
      "id": "X0UUB32aPpT3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at our data."
      ],
      "metadata": {
        "id": "2aJwQjsSxHFm"
      },
      "id": "2aJwQjsSxHFm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bd2d50e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_wine = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", delimiter=\";\")\n",
        "df_wine.head()"
      ],
      "id": "5bd2d50e"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3JgqpD-XG17"
      },
      "execution_count": null,
      "outputs": [],
      "id": "q3JgqpD-XG17"
    },
    {
      "cell_type": "code",
      "source": [
        "df_wine.quality.describe()"
      ],
      "metadata": {
        "id": "MgiHwcpk5tW4"
      },
      "execution_count": null,
      "outputs": [],
      "id": "MgiHwcpk5tW4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Vertex AI SDK for Python: To get started using Vertex AI, you must [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)."
      ],
      "metadata": {
        "id": "bY1jTpkWn0r9"
      },
      "id": "bY1jTpkWn0r9"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "83CNwqe_qZ7Z"
      },
      "id": "83CNwqe_qZ7Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP6fkF3rPpT3"
      },
      "outputs": [],
      "source": [
        "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
      ],
      "id": "zP6fkF3rPpT3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "define_component:wine_classification"
      ],
      "metadata": {
        "id": "XgKUAJ1rp8SZ"
      },
      "id": "XgKUAJ1rp8SZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the use of the `@component()` decorator in the definitions below. Optionally, you can set a list of packages for the component to install. That is, list the base image to use (the default is a Python 3.7 image), and the name of a component YAML file to generate, so that the component definition can be shared and reused."
      ],
      "metadata": {
        "id": "rGqDSrVhrHio"
      },
      "id": "rGqDSrVhrHio"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GaEjh1PWTdp4"
      },
      "execution_count": null,
      "outputs": [],
      "id": "GaEjh1PWTdp4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## First component: read the wine quality dataset and store it in Google Cloud Storage\n",
        "Also let's do some preprocessing as we always do in ML tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "2QRloZ9lLTLU"
      },
      "id": "2QRloZ9lLTLU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51b051c9"
      },
      "outputs": [],
      "source": [
        "@component(\n",
        "  packages_to_install=[\"pandas\", \"numpy==1.23.5\", \"pyarrow\", \"scikit-learn==1.2.2\"],\n",
        "  base_image=\"python:3.9\",\n",
        "  #output_component_file=\"get_wine_data.yaml\"\n",
        ")\n",
        "def get_wine_data(\n",
        "  url: str, # Revert to standard parameter definition\n",
        "  # Use Output[T] to get a metadata-rich handle to the output artifact of type `Dataset`.\n",
        "  # the artifact already has path in the place, where we run the pipeline\n",
        "  dataset_train: Output[Dataset],\n",
        "  dataset_test: Output[Dataset]\n",
        "):\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from sklearn.model_selection import train_test_split\n",
        "\n",
        "  df_wine = pd.read_csv(url, delimiter=\";\")\n",
        "  df_wine['best_quality'] = df_wine.quality.apply(lambda x: int(x>=7))\n",
        "  df_wine['target'] = df_wine.best_quality\n",
        "  df_wine.drop(\n",
        "      columns=['quality', 'total sulfur dioxide', 'best_quality'],\n",
        "      inplace=True\n",
        "  )\n",
        "\n",
        "  train, test = train_test_split(df_wine, test_size=0.3)\n",
        "  train.to_csv(dataset_train.path + \".csv\" , index=False)\n",
        "  test.to_csv(dataset_test.path + \".csv\" , index=False)"
      ],
      "id": "51b051c9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de33e87f"
      },
      "source": [
        "## Train the wine quality model\n"
      ],
      "id": "de33e87f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a50fc15"
      },
      "outputs": [],
      "source": [
        "@component(\n",
        "  packages_to_install = [\n",
        "      \"pandas\",\n",
        "      \"numpy==1.23.5\",\n",
        "      \"scikit-learn==1.2.2\"\n",
        "  ], base_image=\"python:3.9\",\n",
        ")\n",
        "def train_winequality(\n",
        "  # Use Input[T] to get a metadata-rich handle to the\n",
        "  # input artifact of type `Dataset`.\n",
        "  dataset:  Input[Dataset],\n",
        "  model: Output[Model],\n",
        "):\n",
        "  import pickle\n",
        "  import pandas as pd\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "  data = pd.read_csv(dataset.path+\".csv\")\n",
        "  model_rf = RandomForestClassifier(n_estimators=10)\n",
        "  model_rf.fit(\n",
        "      data.drop(columns=[\"target\"]),\n",
        "      data.target,\n",
        "  )\n",
        "  model.metadata[\"framework\"] = \"RF\"\n",
        "  file_name = model.path + \".pkl\"\n",
        "  with open(file_name, 'wb') as file:\n",
        "      pickle.dump(model_rf, file)"
      ],
      "id": "9a50fc15"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdec3aea"
      },
      "source": [
        "## Evaluate the model\n",
        "The results of evaluation will be written in the file in GCP."
      ],
      "id": "fdec3aea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1b304bb"
      },
      "outputs": [],
      "source": [
        "@component(\n",
        "  packages_to_install = [\n",
        "      \"pandas\",\n",
        "      \"numpy==1.23.5\",\n",
        "      \"scikit-learn==1.2.2\"\n",
        "  ], base_image=\"python:3.9\",\n",
        ")\n",
        "def winequality_evaluation(\n",
        "  test_set:  Input[Dataset],\n",
        "  rf_winequality_model: Input[Model],\n",
        "  thresholds_dict_str: str,\n",
        "  metrics: Output[ClassificationMetrics],\n",
        "  kpi: Output[Metrics]\n",
        ") -> NamedTuple(\"output\", [(\"deploy\", str)]):\n",
        "\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  import pandas as pd\n",
        "  import logging\n",
        "  import pickle\n",
        "  from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score\n",
        "  import json\n",
        "  import typing\n",
        "\n",
        "  def threshold_check(val1, val2):\n",
        "      cond = \"false\"\n",
        "      if val1 >= val2 :\n",
        "          cond = \"true\"\n",
        "      return cond\n",
        "\n",
        "  data = pd.read_csv(test_set.path+\".csv\")\n",
        "  file_name = rf_winequality_model.path + \".pkl\"\n",
        "  with open(file_name, 'rb') as file:\n",
        "      model = pickle.load(file)\n",
        "\n",
        "  X_test = data.drop(columns=[\"target\"])\n",
        "  y_target = data.target\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  y_scores =  model.predict_proba(X_test)[:, 1]\n",
        "  fpr, tpr, thresholds = roc_curve(\n",
        "        y_true=data.target.to_numpy(), y_score=y_scores, pos_label=True\n",
        "  )\n",
        "  metrics.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\n",
        "\n",
        "  metrics.log_confusion_matrix(\n",
        "      [\"False\", \"True\"],\n",
        "      confusion_matrix(\n",
        "          data.target, y_pred\n",
        "      ).tolist(),\n",
        "  )\n",
        "\n",
        "  accuracy = accuracy_score(data.target, y_pred.round())\n",
        "  thresholds_dict = json.loads(thresholds_dict_str)\n",
        "  rf_winequality_model.metadata[\"accuracy\"] = float(accuracy)\n",
        "  kpi.log_metric(\"accuracy\", float(accuracy))\n",
        "  deploy = threshold_check(float(accuracy), int(thresholds_dict['roc']))\n",
        "  return (deploy,)"
      ],
      "id": "c1b304bb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "139b5ad2"
      },
      "source": [
        "## Deploy model"
      ],
      "id": "139b5ad2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ae07652"
      },
      "outputs": [],
      "source": [
        "@component(\n",
        "  packages_to_install=[\"google-cloud-aiplatform\", \"scikit-learn==1.0.0\",  \"kfp\"],\n",
        "  base_image=\"python:3.9\",\n",
        "  #output_component_file=\"model_winequality_coponent.yml\"\n",
        ")\n",
        "def deploy_winequality(\n",
        "  model: Input[Model],\n",
        "  project: str,\n",
        "  region: str,\n",
        "  serving_container_image_uri : str,\n",
        "  vertex_endpoint: Output[Artifact],\n",
        "  vertex_model: Output[Model]\n",
        "):\n",
        "  from google.cloud import aiplatform\n",
        "  aiplatform.init(project=project, location=region)\n",
        "\n",
        "  DISPLAY_NAME  = \"winequality\"\n",
        "  MODEL_NAME = \"winequality-rf\"\n",
        "  ENDPOINT_NAME = \"winequality_endpoint\"\n",
        "\n",
        "  def create_endpoint():\n",
        "      endpoints = aiplatform.Endpoint.list(\n",
        "        filter='display_name=\"{}\"'.format(ENDPOINT_NAME),\n",
        "        order_by='create_time desc',\n",
        "        project=project,\n",
        "        location=region,\n",
        "      )\n",
        "      if len(endpoints) > 0:\n",
        "          return endpoints[0]  # most recently created\n",
        "      else:\n",
        "          return aiplatform.Endpoint.create(\n",
        "            display_name=ENDPOINT_NAME, project=project, location=region\n",
        "        )\n",
        "  endpoint = create_endpoint()\n",
        "\n",
        "  #Import a model programmatically\n",
        "  model_upload = aiplatform.Model.upload(\n",
        "      display_name = DISPLAY_NAME,\n",
        "      artifact_uri = model.uri.replace(\"model\", \"\"),\n",
        "      serving_container_image_uri = serving_container_image_uri,\n",
        "      serving_container_health_route=f\"/v1/models/{MODEL_NAME}\",\n",
        "      serving_container_predict_route=f\"/v1/models/{MODEL_NAME}:predict\",\n",
        "      serving_container_environment_variables={\n",
        "      \"MODEL_NAME\": MODEL_NAME,\n",
        "  },\n",
        "  )\n",
        "  model_deploy = model_upload.deploy(\n",
        "      machine_type=\"n1-standard-4\",\n",
        "      endpoint=endpoint,\n",
        "      traffic_split={\"0\": 100},\n",
        "      deployed_model_display_name=DISPLAY_NAME,\n",
        "  )\n",
        "\n",
        "  # Save the resource name to the output params\n",
        "  vertex_model.uri = model_deploy.resource_name"
      ],
      "id": "0ae07652"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7902a0f7"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "DISPLAY_NAME = 'pipeline-winequality-job{}'.format(TIMESTAMP)"
      ],
      "id": "7902a0f7"
    },
    {
      "cell_type": "code",
      "source": [
        "DISPLAY_NAME"
      ],
      "metadata": {
        "id": "DNfk8o3YfdvK"
      },
      "id": "DNfk8o3YfdvK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f98bd8c3"
      },
      "source": [
        "## Create the Pipeline itself\n",
        "\n",
        "Once you have created all the needed components define the pipeline and then compile it into a `.json` file."
      ],
      "id": "f98bd8c3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJsGtfhtcqgs"
      },
      "outputs": [],
      "source": [
        "PIPELINE_ROOT"
      ],
      "id": "FJsGtfhtcqgs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3d5f227"
      },
      "outputs": [],
      "source": [
        "@dsl.pipeline(\n",
        "  # Default pipeline root. You can override it when submitting the pipeline.\n",
        "  pipeline_root=PIPELINE_ROOT,\n",
        "  # A name for the pipeline. Use to determine the pipeline Context.\n",
        "  name=\"pipeline-winequality\",\n",
        ")\n",
        "def pipeline(\n",
        "  url: str = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
        "  project: str = PROJECT_ID,\n",
        "  region: str = REGION,\n",
        "  display_name: str = DISPLAY_NAME,\n",
        "  api_endpoint: str = REGION+\"-aiplatform.googleapis.com\",\n",
        "  thresholds_dict_str: str = '{\"roc\":0.8}',\n",
        "  serving_container_image_uri: str = \"europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n",
        "):\n",
        "  data_op = get_wine_data(url=url)\n",
        "  train_model_op = train_winequality(dataset=data_op.outputs[\"dataset_train\"])\n",
        "  model_evaluation_op = winequality_evaluation(\n",
        "      test_set=data_op.outputs[\"dataset_test\"],\n",
        "      rf_winequality_model=train_model_op.outputs[\"model\"],\n",
        "      thresholds_dict_str = thresholds_dict_str, # I deploy the model anly if the model performance is above the threshold\n",
        "  )\n",
        "\n",
        "  with dsl.Condition(\n",
        "      model_evaluation_op.outputs[\"deploy\"]==\"true\",\n",
        "      name=\"deploy-winequality\",\n",
        "  ):\n",
        "      deploy_model_op = deploy_winequality(\n",
        "        model=train_model_op.outputs['model'],\n",
        "        project=project,\n",
        "        region=region,\n",
        "        serving_container_image_uri = serving_container_image_uri,\n",
        "      )"
      ],
      "id": "d3d5f227"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ba00f47"
      },
      "source": [
        "### Compile and run the pipeline"
      ],
      "id": "6ba00f47"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d68ec6e4"
      },
      "outputs": [],
      "source": [
        "compiler.Compiler().compile(\n",
        "    pipeline_func=pipeline,\n",
        "    package_path='ml_winequality.json'\n",
        ")"
      ],
      "id": "d68ec6e4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c68be6e6"
      },
      "source": [
        "The pipeline compilation generates the **ml_winequality.json** job spec file."
      ],
      "id": "c68be6e6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1e47a43"
      },
      "outputs": [],
      "source": [
        "### Create a run"
      ],
      "id": "f1e47a43"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_YjyECUdeDS"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ],
      "id": "N_YjyECUdeDS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4lycTgRtNkv"
      },
      "outputs": [],
      "source": [
        "# might be needed if we restarted the notebook before\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ],
      "id": "e4lycTgRtNkv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b24bac81"
      },
      "outputs": [],
      "source": [
        "start_pipeline = pipeline_jobs.PipelineJob(\n",
        "  display_name=\"winequality-pipeline\",\n",
        "  template_path=\"ml_winequality.json\",\n",
        "  enable_caching=True,\n",
        "  location=REGION\n",
        ")"
      ],
      "id": "b24bac81"
    },
    {
      "cell_type": "code",
      "source": [
        "#stop execution\n",
        "raise SystemExit(1)"
      ],
      "metadata": {
        "id": "vZFcPN1VXjc4"
      },
      "id": "vZFcPN1VXjc4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq0C91EItkmP"
      },
      "outputs": [],
      "source": [
        "start_pipeline.run(service_account=SERVICE_ACCOUNT)"
      ],
      "id": "gq0C91EItkmP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcb26db0"
      },
      "source": [
        "### List all models"
      ],
      "id": "dcb26db0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e9c6097"
      },
      "outputs": [],
      "source": [
        "! gcloud ai models list --region={REGION} --project={PROJECT_ID} --filter={DISPLAY_NAME}"
      ],
      "id": "8e9c6097"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1de419e"
      },
      "source": [
        "### Schedule pipeline"
      ],
      "id": "a1de419e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbce39c8"
      },
      "source": [
        "The scheduled jobs are supported by the Cloud Scheduler and Cloud Functions.\n",
        "Check that the APIs Cloud Scheduler, Cloud Functions are enabled.\n",
        "\n",
        "Below is a code to create a scheduled pipeline run"
      ],
      "id": "fbce39c8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2cf02fc"
      },
      "outputs": [],
      "source": [
        "from kfp.v2.google.client import AIPlatformClient\n",
        "\n",
        "api_client = AIPlatformClient(\n",
        "                project_id=PROJECT_ID,\n",
        "                region=REGION,\n",
        "                )\n",
        "\n",
        "response = api_client.create_schedule_from_job_spec(\n",
        "    enable_caching=True,\n",
        "    job_spec_path=\"ml_winequality.json\",\n",
        "    schedule=\"0 0 * * 1\", # once per week on Monday\n",
        "    time_zone=\"Europe/Brussels\",  # change this as necessary\n",
        "    parameter_values={\"display_name\": DISPLAY_NAME},\n",
        "    pipeline_root=PIPELINE_ROOT,  # this argument is necessary if you did not specify PIPELINE_ROOT as part of the pipeline definition.\n",
        "    #service_account=SERVICE_ACCOUNT,\n",
        ")\n"
      ],
      "id": "c2cf02fc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bfc56a4"
      },
      "source": [
        "Once the scheduled job is created, you can see it listed in the Cloud Scheduler panel in the Console."
      ],
      "id": "3bfc56a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a14ebfea"
      },
      "source": [
        "# Get predictions from endpoint"
      ],
      "id": "a14ebfea"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check our model performance by calling endpoint. And for sure we can call it for the new data coming."
      ],
      "metadata": {
        "id": "dSmxv1ehde9I"
      },
      "id": "dSmxv1ehde9I"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gcsfs"
      ],
      "metadata": {
        "id": "GR46l2oH_274"
      },
      "id": "GR46l2oH_274",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here is how to read data from GCS. You need to be authorized!\n",
        "\n",
        "import gcsfs\n",
        "import pandas as pd\n",
        "\n",
        "fs = gcsfs.GCSFileSystem()\n",
        "\n",
        "data_path = 'gs://gcs-bucket-name-wine2/pipeline_root_simple_example/219162896674/pipeline-winequality-20250712224306/get-wine-data_1228575498100015104/dataset_test.csv'\n",
        "\n",
        "with fs.open(data_path, 'rb') as f:\n",
        "    test_df = pd.read_csv(f, nrows=10) # let's read just a chunk of data to speed up data load\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "vdVYOgku_s2Z"
      },
      "id": "vdVYOgku_s2Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create instances\n",
        "instances = test_df.drop(columns='target').values.tolist()"
      ],
      "metadata": {
        "id": "JFlbY9UOeTjU"
      },
      "id": "JFlbY9UOeTjU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instances"
      ],
      "metadata": {
        "id": "QeYyCAwMebBF"
      },
      "id": "QeYyCAwMebBF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENDPOINT_ID = !(gcloud ai endpoints list --region=$REGION \\\n",
        "              --format='value(ENDPOINT_ID)'\\\n",
        "              --filter=display_name=$ENDPOINT_NAME \\\n",
        "              --sort-by=creationTimeStamp)"
      ],
      "metadata": {
        "id": "ThdpwIcMl-2Z"
      },
      "id": "ThdpwIcMl-2Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f69cd649"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "ENDPOINT_NAME=\"winequality_endpoint\"\n",
        "\n",
        "# get the endpoint id\n",
        "endpoint_output = !(gcloud ai endpoints list --region=$REGION \\\n",
        "              --format='value(ENDPOINT_ID)'\\\n",
        "              --filter=display_name=$ENDPOINT_NAME \\\n",
        "              --sort-by=creationTimeStamp --project=$PROJECT_ID)\n",
        "\n",
        "if not endpoint_output:\n",
        "    raise ValueError(f\"No endpoint found with display name {ENDPOINT_NAME}\")\n",
        "\n",
        "# Extract the actual endpoint ID from the command output\n",
        "# The actual ID should be the last line of the output\n",
        "ENDPOINT_ID = endpoint_output[-1].strip()\n",
        "\n",
        "\n",
        "# aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "endpoint = aiplatform.Endpoint(ENDPOINT_ID)\n",
        "prediction = endpoint.predict(instances=instances)"
      ],
      "id": "f69cd649"
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.predictions"
      ],
      "metadata": {
        "id": "9lLslB-dfcoM"
      },
      "id": "9lLslB-dfcoM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(map(int, prediction.predictions)), test_df.target.tolist()"
      ],
      "metadata": {
        "id": "WTcsB8Ro-wPF"
      },
      "id": "WTcsB8Ro-wPF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the model performance is quite good. At least on those 10 records :)"
      ],
      "metadata": {
        "id": "YpE1Jy2Sf5pe"
      },
      "id": "YpE1Jy2Sf5pe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf61af7d"
      },
      "source": [
        "# Test the batch prediction\n",
        "\n",
        "Takes some time, but at least you will have a code and understanding of how to run it.\n",
        "\n"
      ],
      "id": "cf61af7d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e748c28b"
      },
      "outputs": [],
      "source": [
        "# Define variables\n",
        "job_display_name = \"winequality-batch-prediction-job\"\n",
        "MODEL_NAME=\"winequality\"\n",
        "ENDPOINT_NAME=\"winequality_endpoint\"\n",
        "BUCKET_URI=\"gs://tokyo-charge-378510-bucket-winequality/pipeline_root_wine/24871937313/pipeline-winequality-20230222111722/get_wine_data_5671759263626690560\"\n",
        "input_file_name=\"dataset_test.csv\"\n",
        "\n",
        "# Get model id\n",
        "MODEL_ID=!(gcloud ai models list --region=$REGION \\\n",
        "           --filter=display_name=$MODEL_NAME)\n",
        "MODEL_ID=MODEL_ID[2].split(\" \")[0]\n",
        "\n",
        "model_resource_name = f'projects/{PROJECT_ID}/locations/{REGION}/models/{MODEL_ID}'\n",
        "gcs_source= [f\"{BUCKET_URI}/{input_file_name}\"]\n",
        "gcs_destination_prefix=f\"{BUCKET_URI}/output\"\n",
        "\n",
        "def batch_prediction_job(\n",
        "    project: str,\n",
        "    location: str,\n",
        "    model_resource_name: str,\n",
        "    job_display_name: str,\n",
        "    gcs_source: str,\n",
        "    gcs_destination_prefix: str,\n",
        "    machine_type: str,\n",
        "    starting_replica_count: int = 1, # The number of nodes for this batch prediction job.\n",
        "    max_replica_count: int = 1,\n",
        "):\n",
        "    aiplatform.init(project=project, location=location)\n",
        "\n",
        "    model = aiplatform.Model(model_resource_name)\n",
        "\n",
        "    batch_prediction_job = model.batch_predict(\n",
        "        job_display_name=job_display_name,\n",
        "        instances_format='csv', #json\n",
        "        gcs_source=[f\"{BUCKET_URI}/{input_file_name}\"],\n",
        "        gcs_destination_prefix=f\"{BUCKET_URI}/output\",\n",
        "        machine_type=machine_type, # must be present\n",
        "    )\n",
        "    batch_prediction_job.wait()\n",
        "    print(batch_prediction_job.display_name)\n",
        "    print(batch_prediction_job.state)\n",
        "    return batch_prediction_job\n",
        "\n",
        "batch_prediction_job(PROJECT_ID, REGION, model_resource_name, job_display_name, gcs_source, gcs_destination_prefix, machine_type=\"n1-standard-2\")"
      ],
      "id": "e748c28b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean up!"
      ],
      "metadata": {
        "id": "7v5R-N5bgSWz"
      },
      "id": "7v5R-N5bgSWz"
    },
    {
      "cell_type": "code",
      "source": [
        "# setup the following parameters manually\n",
        "\n",
        "DISPLAY_NAME = \"pipeline-winequality-20230222111722\"\n",
        "BUCKET_URI = \"gs://tokyo-charge-378510-bucket-winequality/pipeline_root_wine/24871937313/aaa\""
      ],
      "metadata": {
        "id": "8r9QmStlgikz"
      },
      "id": "8r9QmStlgikz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "delete_pipeline = True\n",
        "delete_bucket = True\n",
        "\n",
        "try:\n",
        "    if delete_pipeline and \"DISPLAY_NAME\" in globals():\n",
        "        pipelines = aiplatform.PipelineJob.list(\n",
        "            filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
        "        )\n",
        "        pipeline = pipelines[0]\n",
        "        aiplatform.PipelineJob.delete(pipeline.resource_name)\n",
        "        print(\"Deleted pipeline:\", pipeline)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil rm -r $BUCKET_URI"
      ],
      "metadata": {
        "id": "OXk8Udktgezz"
      },
      "id": "OXk8Udktgezz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil rm -r $BUCKET_URI"
      ],
      "metadata": {
        "id": "Q_NsbE0aheOY"
      },
      "id": "Q_NsbE0aheOY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we need to go the the Vertex AI and delete deployed models.\n",
        "This is important as everyhting we store on cloud costs something."
      ],
      "metadata": {
        "id": "zC4dso77jpPn"
      },
      "id": "zC4dso77jpPn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1bf95ab"
      },
      "source": [
        "# Define the get_wine_data component using a YAML specification\n",
        "get_wine_data_yaml = \"\"\"\n",
        "name: Get Wine Data\n",
        "description: Reads the wine quality dataset and splits it into train and test sets.\n",
        "inputs:\n",
        "  - name: url\n",
        "    type: String\n",
        "outputs:\n",
        "  - name: dataset_train\n",
        "    type: Dataset\n",
        "  - name: dataset_test\n",
        "    type: Dataset\n",
        "implementation:\n",
        "  container:\n",
        "    image: python:3.9\n",
        "    command:\n",
        "      - python\n",
        "      - -c\n",
        "      - |\n",
        "        import pandas as pd\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        import argparse\n",
        "\n",
        "        parser = argparse.ArgumentParser()\n",
        "        parser.add_argument('--url', type=str)\n",
        "        parser.add_argument('--dataset_train_path', type=str)\n",
        "        parser.add_argument('--dataset_test_path', type=str)\n",
        "        args = parser.parse_args()\n",
        "\n",
        "        df_wine = pd.read_csv(args.url, delimiter=\";\")\n",
        "        df_wine['best_quality'] = df_wine.quality.apply(lambda x: int(x>=7))\n",
        "        df_wine['target'] = df_wine.best_quality\n",
        "        df_wine.drop(\n",
        "            columns=['quality', 'total sulfur dioxide', 'best_quality'],\n",
        "            inplace=True\n",
        "        )\n",
        "\n",
        "        train, test = train_test_split(df_wine, test_size=0.3)\n",
        "        train.to_csv(args.dataset_train_path + \".csv\" , index=False)\n",
        "        test.to_csv(args.dataset_test_path + \".csv\" , index=False)\n",
        "\n",
        "    args:\n",
        "      - --url\n",
        "      - {inputValue: url}\n",
        "      - --dataset_train_path\n",
        "      - {outputPath: dataset_train}\n",
        "      - --dataset_test_path\n",
        "      - {outputPath: dataset_test}\n",
        "\"\"\"\n",
        "\n",
        "from kfp import components\n",
        "get_wine_data_op = components.load_component_from_yaml(get_wine_data_yaml)"
      ],
      "id": "a1bf95ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a537e633"
      },
      "source": [
        "@dsl.pipeline(\n",
        "  # Default pipeline root. You can override it when submitting the pipeline.\n",
        "  pipeline_root=PIPELINE_ROOT,\n",
        "  # A name for the pipeline. Use to determine the pipeline Context.\n",
        "  name=\"pipeline-winequality\",\n",
        ")\n",
        "def pipeline(\n",
        "  url: str = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
        "  project: str = PROJECT_ID,\n",
        "  region: str = REGION,\n",
        "  display_name: str = DISPLAY_NAME,\n",
        "  api_endpoint: str = REGION+\"-aiplatform.googleapis.com\",\n",
        "  thresholds_dict_str: str = '{\"roc\":0.8}',\n",
        "  serving_container_image_uri: str = \"europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n",
        "):\n",
        "  data_op = get_wine_data_op(url=url)\n",
        "  train_model_op = train_winequality(dataset=data_op.outputs[\"dataset_train\"])\n",
        "  model_evaluation_op = winequality_evaluation(\n",
        "      test_set=data_op.outputs[\"dataset_test\"],\n",
        "      rf_winequality_model=train_model_op.outputs[\"model\"],\n",
        "      thresholds_dict_str = thresholds_dict_str, # I deploy the model anly if the model performance is above the threshold\n",
        "  )\n",
        "\n",
        "  with dsl.Condition(\n",
        "      model_evaluation_op.outputs[\"deploy\"]==\"true\",\n",
        "      name=\"deploy-winequality\",\n",
        "  ):\n",
        "      deploy_model_op = deploy_winequality(\n",
        "        model=train_model_op.outputs['model'],\n",
        "        project=project,\n",
        "        region=region,\n",
        "        serving_container_image_uri = serving_container_image_uri,\n",
        "      )"
      ],
      "id": "a537e633",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "environment": {
      "name": "tf2-gpu.2-3.m75",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m75"
    },
    "kernelspec": {
      "display_name": "vetex_env",
      "language": "python",
      "name": "vetex_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}